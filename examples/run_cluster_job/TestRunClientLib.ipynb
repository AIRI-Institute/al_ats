{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eacad9a-9296-4994-8243-cc00fd210883",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example notebook for running jobs on MlSpace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0588aa9b-4ec3-4d59-a39a-9a72f90fe251",
   "metadata": {},
   "source": [
    "## Важные детали\n",
    "0. В данном ноутбуке используется client_lib для запуска задач - эта библиотека работает только на инстансах mlspace. Поэтому алгоритм запуска задач при помощи client_lib следующий - необходимо создать бесплатный инстанс с cpu, и на нем выполнить дальнейшие шаги. Другой вариант - запуск при помощи api - также требует созданного инстанса для получения ключей для авторизации, но при этом запустить задачу при помощи api можно удаленно, подробнее это описано [здесь](https://github.com/sbercloud-ai/aicloud-examples/blob/master/public-api-example/public-api-examples-notebook.ipynb).\n",
    "1. Задача запускается внутри контейнера, который собирается либо на основе одного из [доступных образов](https://mlspace.aicloud.sbercloud.ru/mlspace/datahub-catalog), либо на основе своего образа - он собирается при помощи базового образа и requirements.txt.\n",
    "2. При запуске задачи из контейнера нет доступа к интернету, поэтому все библиотеки нужно установить на этапе сборки.\n",
    "3. Контейнер и инстанс, из которого запускается задача, имеют общее дисковое пространство. Поэтому если для задачи необходим датасет/модель/что-то еще, то их можно заранее сохранить на диск и загрузить сохраненную копию при обучении.\n",
    "4. Важно: задачи в контейнере запускаются от имени другого пользователя (не совпадает с пользователем в инстансе). Поэтому при сохранении данных в домашней директории на инстансе необходимо копировать их в директорию пользователя контейнера (актуально для huggingface, т. к. часть его файлов кэшируется в ~/).\n",
    "5. При помощи client_lib.Job на данный момент лучше запускать только .py файлы (.sh скрипты можно обернуть в простую обертку (например, os.system('run.sh'))) Также можно запускать и .sh скрипты, но на данный момент при запуске они автоматически будут выполняться в параллельном режиме при запуске на нескольких нодах/инстансах.\n",
    "6. Текущий статус задачи и логи можно смотреть не только при помощи client_lib, но и в разделе Environments->Задачи и окружения->Задачи.\n",
    "\n",
    "Остальные детали и пример запуска задачи (на примере эксперимента из репозитория active_learning) представлены дальше. Больше информации по client_lib можно найти по ссылкам ([документация](https://docs.sbercloud.ru/aicloud/mlspace/concepts/client-lib.html), [примеры](https://github.com/sbercloud-ai/aicloud-examples/blob/master/quick-start/job_launch_tf2/quick-start-v100.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3488e828-87cd-4dd6-85d0-484f03d27b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import client_lib\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"Скрипт не предназначен для запуска вне кластера\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292fe69e-9633-4e11-8b42-3e0094b1f8e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing part (for active learning)\n",
    "Use a special script for loading and caching all data - active_learning/examples/cache_necessary_files/run.sh. Before calling this script, set used dataset and model in run.sh. After set cache_dir in your training config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42461769-8275-4f02-b4b4-6246d0a5212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b30e726-0f94-44ea-a153-5654c7b332eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this tutorial we will use ./preprocessing_script.sh instead of mentioned above, because we want to have fixed path to cache dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b641f4-111f-4f43-a7c5-0010ee1d49f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-02 17:35:59,862][root][INFO] - .......... Caching model and tokenizer ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 17:36:00.603632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-02 17:36:07,326][root][INFO] - ========== Model distilbert-base-uncased successfully cached ==========\n",
      "[2022-02-02 17:36:14,022][root][INFO] - ========== Tokenizer distilbert-base-uncased successfully cached ==========\n",
      "[2022-02-02 17:36:14,023][root][INFO] - .......... Caching cached dataset ..........\n",
      "[2022-02-02 17:36:15,627][datasets.builder][WARNING] - Using custom data configuration default\n",
      "[2022-02-02 17:36:15,666][datasets.builder][WARNING] - Reusing dataset ag_news (../../../workdir/cache/test_data/data/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "[2022-02-02 17:36:15,712][root][INFO] - ========== Dataset ag_news successfully cached ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 46.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-02 17:36:17,020][root][INFO] - .......... Caching metrics ..........\n",
      "[2022-02-02 17:36:18,382][root][INFO] - ========== Main metric accuracy successfully cached ==========\n",
      "[2022-02-02 17:36:19,478][root][INFO] - ========== Additional metric f1 successfully cached ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Error executing job with overrides: ['data.dataset_name=ag_news', 'acquisition_model.name=distilbert-base-uncased', 'cache_model_and_dataset=True', 'cache_dir=../../../workdir/cache/test_data']\n",
      "Traceback (most recent call last):\n",
      "  File \"../../active_learning/utils/cache_all_necessary_files.py\", line 40, in main\n",
      "    rmtree(auto_generated_dir)\n",
      "  File \"/home/jovyan/.imgenv-free-cpu-0/lib/python3.7/shutil.py\", line 498, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/home/jovyan/.imgenv-free-cpu-0/lib/python3.7/shutil.py\", line 496, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/home/jovyan/active_learning/examples/run_cluster_job/workdir/run_active_learning/2022-02-02/17-35-55_42_distilbert_base_uncased'\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"chmod a+x preprocessing_script.sh\")\n",
    "os.system(\"./preprocessing_script.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b06e0f7-3f78-41b0-9141-8cccff59ada5",
   "metadata": {},
   "source": [
    "# Build image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734d83f4-e697-4336-bc3b-1bfce9c02549",
   "metadata": {},
   "source": [
    "Before running tasks, one could build an image using available base docker images. List of base images could be found here: https://mlspace.aicloud.sbercloud.ru/mlspace/datahub-catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63382197-0c74-47cf-822a-2b461067da7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-b07219:latest',\n",
       " 'cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-8bd99f:latest',\n",
       " 'cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-6f2439:latest',\n",
       " 'cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-8c76b2:latest',\n",
       " 'cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-07cf30:latest',\n",
       " 'cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-576f48:latest',\n",
       " 'cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-897c49:latest',\n",
       " 'cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-8e2201:latest',\n",
       " 'cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-b02978:latest']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available images - if you created images before, you can reuse one of them\n",
    "client_lib.get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "838bbb3a-4ca0-46ee-b167-aff413faa482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ImageBuildJob \"{\\'image\\': \\'cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-2368f0\\', \\'name\\': \\'image-build-job-jp9t6\\', \\'status\\': \\'ok\\'}\" created'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If not, you can create your own image\n",
    "job = client_lib.ImageBuildJob(\n",
    "    from_image=\"cr.msk.sbercloud.ru/aicloud-base-images/cuda10.2:0.0.25\",  # base image\n",
    "    requirements_file=\"/home/jovyan/active_learning/requirements.txt\",  # requirements file\n",
    ")\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d82224-906b-4306-adc7-bb3ba5afae71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cr.msk.sbercloud.ru/728d63df-4bf7-4aaf-ba85-e2e7ceb9feea/job-custom-image-2368f0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.new_image  # image ID, used as an argument for running task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c31044e6-a357-4e09-b4a7-dfb55babf869",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mINFO\u001b[0m[0005] Resolved base name cr.msk.sbercloud.ru/aicloud-base-images/cuda10.2:0.0.25 to cr.msk.sbercloud.ru/aicloud-base-images/cuda10.2:0.0.25 \n",
      "\u001b[36mINFO\u001b[0m[0005] Resolved base name cr.msk.sbercloud.ru/aicloud-base-images/cuda10.2:0.0.25 to cr.msk.sbercloud.ru/aicloud-base-images/cuda10.2:0.0.25 \n",
      "\u001b[36mINFO\u001b[0m[0005] Retrieving image manifest cr.msk.sbercloud.ru/aicloud-base-images/cuda10.2:0.0.25 \n",
      "\u001b[36mINFO\u001b[0m[0008] Retrieving image manifest cr.msk.sbercloud.ru/aicloud-base-images/cuda10.2:0.0.25 \n",
      "\u001b[36mINFO\u001b[0m[0009] Built cross stage deps: map[]                \n",
      "\u001b[36mINFO\u001b[0m[0009] Retrieving image manifest cr.msk.sbercloud.ru/aicloud-base-images/cuda10.2:0.0.25 \n",
      "\u001b[36mINFO\u001b[0m[0009] Retrieving image manifest cr.msk.sbercloud.ru/aicloud-base-images/cuda10.2:0.0.25 \n",
      "\u001b[36mINFO\u001b[0m[0009] Unpacking rootfs as cmd RUN if [ -e /context/requirements.txt ]; then  pip install --user --no-cache -r /context/requirements.txt; fi requires it. \n",
      "\u001b[36mINFO\u001b[0m[0319] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0327] RUN if [ -e /context/requirements.txt ]; then  pip install --user --no-cache -r /context/requirements.txt; fi \n",
      "\u001b[36mINFO\u001b[0m[0327] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0327] args: [-c if [ -e /context/requirements.txt ]; then  pip install --user --no-cache -r /context/requirements.txt; fi] \n",
      "Collecting hydra-core==1.1.0\n",
      "  Downloading hydra_core-1.1.0-py3-none-any.whl (144 kB)\n",
      "Collecting datasets==1.18.0\n",
      "  Downloading datasets-1.18.0-py3-none-any.whl (311 kB)\n",
      "Collecting allennlp==2.9.0\n",
      "  Downloading allennlp-2.9.0-py3-none-any.whl (716 kB)\n",
      "Collecting rouge-score==0.0.4\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting modAL==0.4.1\n",
      "  Downloading modAL-0.4.1-py3-none-any.whl (27 kB)\n",
      "Collecting catalyst==21.12\n",
      "  Downloading catalyst-21.12-py2.py3-none-any.whl (544 kB)\n",
      "Collecting plotly==5.5.0\n",
      "  Downloading plotly-5.5.0-py2.py3-none-any.whl (26.5 MB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.9.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "Collecting kaleido==0.2.1\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "Collecting seqeval==1.2.2\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting nlpaug==1.1.10\n",
      "  Downloading nlpaug-1.1.10-py3-none-any.whl (410 kB)\n",
      "Collecting ruamel.yaml==0.17.20\n",
      "  Downloading ruamel.yaml-0.17.20-py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: tqdm in /home/user/conda/lib/python3.7/site-packages (from -r /context/requirements.txt (line 13)) (4.62.3)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "Collecting mlflow==1.7.2\n",
      "  Downloading mlflow-1.7.2-py3-none-any.whl (16.0 MB)\n",
      "Collecting KDEpy==1.1.0\n",
      "  Downloading KDEpy-1.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (420 kB)\n",
      "Collecting hnswlib==0.6.0\n",
      "  Downloading hnswlib-0.6.0.tar.gz (30 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting aioredis\n",
      "  Downloading aioredis-2.0.1-py3-none-any.whl (71 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-1.10.2-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting ray==1.9.1\n",
      "  Downloading ray-1.9.1-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
      "Collecting transformers==4.13.0\n",
      "  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting nltk==3.6.5\n",
      "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
      "Collecting sacrebleu==1.5.0\n",
      "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
      "Collecting pytest==4.4.1\n",
      "  Downloading pytest-4.4.1-py2.py3-none-any.whl (223 kB)\n",
      "Collecting pytest-runner\n",
      "  Downloading pytest_runner-5.3.1-py3-none-any.whl (7.1 kB)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting omegaconf==2.1.*\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/user/conda/lib/python3.7/site-packages (from datasets==1.18.0->-r /context/requirements.txt (line 2)) (2.26.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting pyarrow!=4.0.0,>=3.0.0\n",
      "  Downloading pyarrow-6.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.10.1-py3-none-any.whl (17 kB)\n",
      "Collecting fairscale==0.4.5\n",
      "  Downloading fairscale-0.4.5.tar.gz (240 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting spacy<3.3,>=2.1.0\n",
      "  Downloading spacy-3.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-8.12.0-py3-none-any.whl (54 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "Collecting torchvision<0.12.0,>=0.8.1\n",
      "  Downloading torchvision-0.11.3-cp37-cp37m-manylinux1_x86_64.whl (23.2 MB)\n",
      "Collecting tensorboardX>=1.2\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "Collecting lmdb\n",
      "  Downloading lmdb-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (298 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting jsonnet>=0.10.0\n",
      "  Downloading jsonnet-0.18.0.tar.gz (592 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting checklist==0.0.11\n",
      "  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting base58\n",
      "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting termcolor==1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.6.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
      "Collecting wandb<0.13.0,>=0.10.0\n",
      "  Downloading wandb-0.12.10-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting filelock<3.5,>=3.3\n",
      "  Downloading filelock-3.4.2-py3-none-any.whl (9.9 kB)\n",
      "Collecting cached-path<2.0.0,>=1.0.2\n",
      "  Downloading cached_path-1.0.2-py3-none-any.whl (26 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/user/conda/lib/python3.7/site-packages (from rouge-score==0.0.4->-r /context/requirements.txt (line 4)) (1.16.0)\n",
      "Collecting hydra-slayer>=0.1.1\n",
      "  Downloading hydra_slayer-0.4.0-py3-none-any.whl (13 kB)\n",
      "Collecting PyYAML>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "Collecting tensorboardX>=1.2\n",
      "  Downloading tensorboardX-2.2-py2.py3-none-any.whl (120 kB)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.6\n",
      "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
      "Collecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
      "Collecting alembic<=1.4.1\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting Flask\n",
      "  Downloading Flask-2.0.2-py3-none-any.whl (95 kB)\n",
      "Collecting sqlparse\n",
      "  Downloading sqlparse-0.4.2-py3-none-any.whl (42 kB)\n",
      "Collecting click>=7.0\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "Collecting simplejson\n",
      "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.16.2.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docker>=4.0.0\n",
      "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Collecting gorilla\n",
      "  Downloading gorilla-0.4.0-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting sqlalchemy<=1.3.13\n",
      "  Downloading SQLAlchemy-1.3.13.tar.gz (6.0 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Collecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting python-dateutil\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.18.7-py3-none-any.whl (17 kB)\n",
      "Collecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting entrypoints\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting attrs\n",
      "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.0.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "Collecting grpcio>=1.28.1\n",
      "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "Collecting jsonschema\n",
      "  Downloading jsonschema-4.4.0-py3-none-any.whl (72 kB)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.2-py3-none-any.whl (173 kB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting py>=1.5.0\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "Collecting atomicwrites>=1.0\n",
      "  Downloading atomicwrites-1.4.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: setuptools in /home/user/conda/lib/python3.7/site-packages (from pytest==4.4.1->-r /context/requirements.txt (line 26)) (58.4.0)\n",
      "Collecting pluggy>=0.9\n",
      "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting munch>=2.5\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting jupyter>=1.0\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting ipywidgets>=7.5\n",
      "  Downloading ipywidgets-7.6.5-py2.py3-none-any.whl (121 kB)\n",
      "Collecting patternfork-nosql\n",
      "  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting iso-639\n",
      "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.29.1-py3-none-any.whl (895 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Collecting async-timeout\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.0.1-py3-none-any.whl (22 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting boto3<2.0,>=1.0\n",
      "  Downloading boto3-1.20.46-py3-none-any.whl (131 kB)\n",
      "Collecting google-cloud-storage<2.0,>=1.0\n",
      "  Downloading google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.7.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.18.0->-r /context/requirements.txt (line 2)) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.18.0->-r /context/requirements.txt (line 2)) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.18.0->-r /context/requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.18.0->-r /context/requirements.txt (line 2)) (2021.10.8)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "Collecting jinja2\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.5.4-py2.py3-none-any.whl (143 kB)\n",
      "Collecting yaspin>=1.0.0\n",
      "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting cached-property\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.18.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
      "Collecting botocore<1.24.0,>=1.23.46\n",
      "  Downloading botocore-1.23.46-py3-none-any.whl (8.5 MB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.13.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (79 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting google-api-core<3.0dev,>=1.29.0\n",
      "  Downloading google_api_core-2.4.0-py2.py3-none-any.whl (111 kB)\n",
      "Collecting google-auth<3.0dev,>=1.25.0\n",
      "  Downloading google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=1.6.0\n",
      "  Downloading google_cloud_core-2.2.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=1.3.0\n",
      "  Downloading google_resumable_media-2.1.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting nbformat>=4.2.0\n",
      "  Downloading nbformat-5.1.3-py3-none-any.whl (178 kB)\n",
      "Collecting ipython-genutils~=0.2.0\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting ipython>=4.0.0\n",
      "  Downloading ipython-7.31.1-py3-none-any.whl (792 kB)\n",
      "Collecting traitlets>=4.3.1\n",
      "  Downloading traitlets-5.1.1-py3-none-any.whl (102 kB)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.0.2-py3-none-any.whl (243 kB)\n",
      "Collecting widgetsnbextension~=3.5.0\n",
      "  Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting ipykernel>=4.5.1\n",
      "  Downloading ipykernel-6.8.0-py3-none-any.whl (128 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (31 kB)\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.4.0-py3-none-any.whl (22 kB)\n",
      "Collecting nbconvert\n",
      "  Downloading nbconvert-6.4.1-py3-none-any.whl (557 kB)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.2.2-py3-none-any.whl (120 kB)\n",
      "Collecting notebook\n",
      "  Downloading notebook-6.4.8-py3-none-any.whl (9.9 MB)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting backports.csv\n",
      "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "Collecting feedparser\n",
      "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
      "Collecting pdfminer.six\n",
      "  Downloading pdfminer.six-20211012-py3-none-any.whl (5.6 MB)\n",
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cherrypy\n",
      "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.54.0-py2.py3-none-any.whl (207 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
      "Collecting tornado<7.0,>=4.2\n",
      "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
      "Collecting nest-asyncio\n",
      "  Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB)\n",
      "Collecting jupyter-client<8.0\n",
      "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
      "Collecting matplotlib-inline<0.2.0,>=0.1.0\n",
      "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\n",
      "Collecting debugpy<2.0,>=1.0.0\n",
      "  Downloading debugpy-1.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
      "Collecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting jedi>=0.16\n",
      "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.26-py3-none-any.whl (375 kB)\n",
      "Collecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
      "Collecting decorator\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting pexpect>4.3\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting jupyter-core\n",
      "  Downloading jupyter_core-4.9.1-py3-none-any.whl (86 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Downloading terminado-0.13.1-py3-none-any.whl (14 kB)\n",
      "Collecting pyzmq>=17\n",
      "  Downloading pyzmq-22.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting argon2-cffi\n",
      "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting Send2Trash>=1.8.0\n",
      "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting cheroot>=8.2.1\n",
      "  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n",
      "Collecting jaraco.collections\n",
      "  Downloading jaraco.collections-3.5.1-py3-none-any.whl (10 kB)\n",
      "Collecting zc.lockfile\n",
      "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting portend>=2.1.1\n",
      "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Downloading nbclient-0.5.10-py3-none-any.whl (69 kB)\n",
      "Collecting bleach\n",
      "  Downloading bleach-4.1.0-py2.py3-none-any.whl (157 kB)\n",
      "Collecting testpath\n",
      "  Downloading testpath-0.5.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: chardet in /home/user/conda/lib/python3.7/site-packages (from pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp==2.9.0->-r /context/requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: cryptography in /home/user/conda/lib/python3.7/site-packages (from pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp==2.9.0->-r /context/requirements.txt (line 3)) (35.0.0)\n",
      "Collecting qtpy\n",
      "  Downloading QtPy-2.0.0-py3-none-any.whl (62 kB)\n",
      "Collecting jaraco.functools\n",
      "  Downloading jaraco.functools-3.5.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting parso<0.9.0,>=0.8.0\n",
      "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tempora>=1.8\n",
      "  Downloading tempora-5.0.1-py3-none-any.whl (15 kB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/user/conda/lib/python3.7/site-packages (from cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp==2.9.0->-r /context/requirements.txt (line 3)) (1.14.6)\n",
      "Collecting jaraco.text\n",
      "  Downloading jaraco.text-3.7.0-py3-none-any.whl (8.6 kB)\n",
      "Collecting jaraco.classes\n",
      "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: pycparser in /home/user/conda/lib/python3.7/site-packages (from cffi>=1.12->cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp==2.9.0->-r /context/requirements.txt (line 3)) (2.20)\n",
      "Collecting jaraco.context>=4.1\n",
      "  Downloading jaraco.context-4.1.1-py3-none-any.whl (4.4 kB)\n",
      "Building wheels for collected packages: seqeval, hnswlib, antlr4-python3-runtime, checklist, fairscale, termcolor, bs4, alembic, databricks-cli, jsonnet, sqlalchemy, promise, iso-639, pathtools, patternfork-nosql, future, python-docx, sgmllib3k\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=255f62ff1cbece5a7ea437339d6435a7e3dd1b4772bc0abc00cf6d99ffa4d3e3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "  Building wheel for hnswlib (pyproject.toml): started\n",
      "  Building wheel for hnswlib (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for hnswlib: filename=hnswlib-0.6.0-cp37-cp37m-linux_x86_64.whl size=1447953 sha256=5199caff0dc3e97299fa68e2ef8e67bc46b02958e6e1009606f24b3c040c6b8c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/1a/ff/c7/b4bde2615029188a2fc9e4bf245d058780d158ccd3fab42668\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=432bdfadbe5805940c76dd5f6efbf8c079ae3ff012381f7f196fc6ee92a892e7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
      "  Building wheel for checklist (setup.py): started\n",
      "  Building wheel for checklist (setup.py): finished with status 'done'\n",
      "  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165633 sha256=bd36da3dc01842cc170dc8a091d361ef25e0db5ed96a39b1e3305a8a58d3f3a2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/6a/8a/07/6446879be434879c27671c83443727d74cecf6b630c8a24d03\n",
      "  Building wheel for fairscale (pyproject.toml): started\n",
      "  Building wheel for fairscale (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fairscale: filename=fairscale-0.4.5-py3-none-any.whl size=297984 sha256=813910ca56e31ba815fd826415aa9cfcdb1fbfa370febf70462377d85ca246c6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/83/d0/90/bcfc419ab267ea41fda54216f0c99e3faf9bab9b38ec760c46\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=46cedaa0b35930da3579c443b357270251e0902270449c590aa1eb9edbceadd9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=6209d6acf06214491df5a056f602522e3885850fe1ce796ab2dde602157a6f81\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "  Building wheel for alembic (setup.py): started\n",
      "  Building wheel for alembic (setup.py): finished with status 'done'\n",
      "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158172 sha256=db9f002dcbb49c80fa20949f0984cee6658bacb1d8b02dc58ac4a52f9ba1b9b7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
      "  Building wheel for databricks-cli (setup.py): started\n",
      "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.16.2-py3-none-any.whl size=106811 sha256=f954751b8ac85ab33bd85c738999f46eba12f5de2481491486978d974eaab919\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/f4/5c/ed/e1ce20a53095f63b27b4964abbad03e59cf3472822addf7d29\n",
      "  Building wheel for jsonnet (setup.py): started\n",
      "  Building wheel for jsonnet (setup.py): finished with status 'done'\n",
      "  Created wheel for jsonnet: filename=jsonnet-0.18.0-cp37-cp37m-linux_x86_64.whl size=4001735 sha256=b927e0b14901a11e270a3c8914d129407f7a6d890f2df6c706c1c6ee910d4a91\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/a9/63/f9/a653f9c21575e6ff271ee6a49939aa002005174cea6c35919d\n",
      "  Building wheel for sqlalchemy (setup.py): started\n",
      "  Building wheel for sqlalchemy (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.13-cp37-cp37m-linux_x86_64.whl size=1221584 sha256=10cb7c376e3ae049e4e691b950238a5a7a416a10887b3002c3bf5c6b5c25a14a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/b9/ba/77/163f10f14bd489351530603e750c195b0ceceed2f3be2b32f1\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21502 sha256=6737596387d547a582ef0adc8fda80234aca975b3775e74adb4f092d0498d8a8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "  Building wheel for iso-639 (setup.py): started\n",
      "  Building wheel for iso-639 (setup.py): finished with status 'done'\n",
      "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=169061 sha256=6ba24b389a33d87b51f7fcee845b5a18e9b52cc3fe7b2a2507a0bae328768ce7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/47/60/19/6d020fc92138ed1b113a18271e83ea4b5525fe770cb45b9a2e\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=860d111d40041b8b977ae2c08cef3b57a3e62d5838a83993529db7d830b4dd8e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "  Building wheel for patternfork-nosql (setup.py): started\n",
      "  Building wheel for patternfork-nosql (setup.py): finished with status 'done'\n",
      "  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332806 sha256=1f44270f40c0e1fc25ca8baf42dc916f1726754069ecd6544c07268fe5f83422\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/97/72/8f/5305fe28168f93b658da9ed433b9a1d3ec90594faa0c9aaf4b\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=31db0247e747a22a5de361f3db8b65b37fecdff2a3830ecbbdd2293616e2877a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for python-docx (setup.py): started\n",
      "  Building wheel for python-docx (setup.py): finished with status 'done'\n",
      "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=e75a6b9e9107a27b4e053250e7eae1d5cd83b686b972b188cf44201849b8beea\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=77cf5ebcc4c284c12db78f956af0d69592575f132eb967a3fdb7b1d2110b44ab\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sqmkt1mi/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
      "Successfully built seqeval hnswlib antlr4-python3-runtime checklist fairscale termcolor bs4 alembic databricks-cli jsonnet sqlalchemy promise iso-639 pathtools patternfork-nosql future python-docx sgmllib3k\n",
      "Installing collected packages: zipp, typing-extensions, traitlets, pyrsistent, importlib-resources, importlib-metadata, attrs, wcwidth, tornado, pyzmq, python-dateutil, pyparsing, ptyprocess, parso, nest-asyncio, jupyter-core, jsonschema, ipython-genutils, entrypoints, webencodings, pygments, prompt-toolkit, pickleshare, pexpect, packaging, nbformat, matplotlib-inline, MarkupSafe, jupyter-client, jedi, decorator, backcall, testpath, pyasn1, pandocfilters, nbclient, more-itertools, mistune, jupyterlab-pygments, jinja2, ipython, defusedxml, debugpy, bleach, argon2-cffi-bindings, terminado, Send2Trash, rsa, pytz, pyasn1-modules, protobuf, prometheus-client, nbconvert, jaraco.functools, jaraco.context, ipykernel, cachetools, argon2-cffi, tempora, numpy, notebook, murmurhash, jmespath, jaraco.text, jaraco.classes, googleapis-common-protos, google-auth, cymem, click, catalogue, zc.lockfile, widgetsnbextension, wasabi, typer, srsly, soupsieve, smmap, smart-open, sgmllib3k, regex, qtpy, PyYAML, pydantic, preshed, portend, multidict, lxml, jupyterlab-widgets, joblib, jaraco.collections, google-crc32c, google-api-core, frozenlist, filelock, cheroot, botocore, blis, yarl, wrapt, Werkzeug, tokenizers, thinc, termcolor, spacy-loggers, spacy-legacy, scipy, sacremoses, s3transfer, qtconsole, python-docx, pdfminer.six, pathy, nltk, langcodes, jupyter-console, itsdangerous, ipywidgets, huggingface-hub, google-resumable-media, google-cloud-core, gitdb, future, feedparser, cherrypy, beautifulsoup4, backports.csv, asynctest, async-timeout, aiosignal, yaspin, websocket-client, transformers, torch, threadpoolctl, tabulate, sqlalchemy, spacy, shortuuid, sentry-sdk, python-editor, py, psutil, promise, pluggy, pillow, patternfork-nosql, pathtools, munch, Mako, kiwisolver, jupyter, iso-639, google-cloud-storage, gitpython, fsspec, fonttools, Flask, docker-pycreds, dill, deprecated, cycler, cached-property, boto3, atomicwrites, antlr4-python3-runtime, aiohttp, xxhash, wandb, torchvision, tensorboardX, tenacity, sqlparse, simplejson, sentencepiece, scikit-learn, ruamel.yaml.clib, redis, querystring-parser, pytest, pyarrow, prometheus-flask-exporter, portalocker, pandas, omegaconf, multiprocess, msgpack, matplotlib, lmdb, jsonnet, hydra-slayer, h5py, gunicorn, grpcio, gorilla, fairscale, docker, databricks-cli, cloudpickle, checklist, cached-path, base58, alembic, absl-py, seqeval, sacrebleu, ruamel.yaml, rouge-score, ray, pytest-runner, plotly, nlpaug, modAL, mlflow, KDEpy, kaleido, hydra-core, hnswlib, datasets, catalyst, bs4, allennlp, aioredis\n",
      "  WARNING: The scripts jupyter, jupyter-migrate and jupyter-troubleshoot are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jsonschema is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pygmentize is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-trust is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter-kernel, jupyter-kernelspec and jupyter-run are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-execute is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts iptest, iptest3, ipython and ipython3 are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script send2trash is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter-dejavu and jupyter-nbconvert are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script calc-prorate is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts f2py, f2py3 and f2py3.7 are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter-bundlerextension, jupyter-nbextension, jupyter-notebook and jupyter-serverextension are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script cheroot is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script sacremoses is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pathy is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nltk is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-console is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts futurize and pasteurize are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script cherryd is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script wsdump is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tabulate is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script spacy is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script shortuuid is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mako-render is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script flask is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts wandb and wb are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script sqlformat is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts py.test and pytest are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script plasma_store is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script gunicorn is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts databricks and dbfs are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script base58 is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script alembic is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script sacrebleu is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts ray, ray-operator, rllib, serve and tune are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mlflow is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts catalyst-contrib and catalyst-dl are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script allennlp is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "Successfully installed Flask-2.0.2 KDEpy-1.1.0 Mako-1.1.6 MarkupSafe-2.0.1 PyYAML-6.0 Send2Trash-1.8.0 Werkzeug-2.0.2 absl-py-1.0.0 aiohttp-3.8.1 aioredis-2.0.1 aiosignal-1.2.0 alembic-1.4.1 allennlp-2.9.0 antlr4-python3-runtime-4.8 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 async-timeout-4.0.2 asynctest-0.13.0 atomicwrites-1.4.0 attrs-21.4.0 backcall-0.2.0 backports.csv-1.0.7 base58-2.1.1 beautifulsoup4-4.10.0 bleach-4.1.0 blis-0.7.5 boto3-1.20.46 botocore-1.23.46 bs4-0.0.1 cached-path-1.0.2 cached-property-1.5.2 cachetools-5.0.0 catalogue-2.0.6 catalyst-21.12 checklist-0.0.11 cheroot-8.6.0 cherrypy-18.6.1 click-8.0.3 cloudpickle-2.0.0 cycler-0.11.0 cymem-2.0.6 databricks-cli-0.16.2 datasets-1.18.0 debugpy-1.5.1 decorator-5.1.1 defusedxml-0.7.1 deprecated-1.2.13 dill-0.3.4 docker-5.0.3 docker-pycreds-0.4.0 entrypoints-0.3 fairscale-0.4.5 feedparser-6.0.8 filelock-3.4.2 fonttools-4.29.1 frozenlist-1.3.0 fsspec-2022.1.0 future-0.18.2 gitdb-4.0.9 gitpython-3.1.26 google-api-core-2.4.0 google-auth-2.6.0 google-cloud-core-2.2.2 google-cloud-storage-1.44.0 google-crc32c-1.3.0 google-resumable-media-2.1.0 googleapis-common-protos-1.54.0 gorilla-0.4.0 grpcio-1.43.0 gunicorn-20.1.0 h5py-3.6.0 hnswlib-0.6.0 huggingface-hub-0.2.1 hydra-core-1.1.0 hydra-slayer-0.4.0 importlib-metadata-4.10.1 importlib-resources-5.4.0 ipykernel-6.8.0 ipython-7.31.1 ipython-genutils-0.2.0 ipywidgets-7.6.5 iso-639-0.4.5 itsdangerous-2.0.1 jaraco.classes-3.2.1 jaraco.collections-3.5.1 jaraco.context-4.1.1 jaraco.functools-3.5.0 jaraco.text-3.7.0 jedi-0.18.1 jinja2-3.0.3 jmespath-0.10.0 joblib-1.1.0 jsonnet-0.18.0 jsonschema-4.4.0 jupyter-1.0.0 jupyter-client-7.1.2 jupyter-console-6.4.0 jupyter-core-4.9.1 jupyterlab-pygments-0.1.2 jupyterlab-widgets-1.0.2 kaleido-0.2.1 kiwisolver-1.3.2 langcodes-3.3.0 lmdb-1.3.0 lxml-4.7.1 matplotlib-3.5.1 matplotlib-inline-0.1.3 mistune-0.8.4 mlflow-1.7.2 modAL-0.4.1 more-itertools-8.12.0 msgpack-1.0.3 multidict-6.0.2 multiprocess-0.70.12.2 munch-2.5.0 murmurhash-1.0.6 nbclient-0.5.10 nbconvert-6.4.1 nbformat-5.1.3 nest-asyncio-1.5.4 nlpaug-1.1.10 nltk-3.6.5 notebook-6.4.8 numpy-1.21.5 omegaconf-2.1.1 packaging-21.3 pandas-1.3.5 pandocfilters-1.5.0 parso-0.8.3 pathtools-0.1.2 pathy-0.6.1 patternfork-nosql-3.6 pdfminer.six-20211012 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.0.0 plotly-5.5.0 pluggy-1.0.0 portalocker-2.3.2 portend-3.1.0 preshed-3.0.6 prometheus-client-0.13.1 prometheus-flask-exporter-0.18.7 promise-2.3 prompt-toolkit-3.0.26 protobuf-3.19.4 psutil-5.9.0 ptyprocess-0.7.0 py-1.11.0 pyarrow-6.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pydantic-1.8.2 pygments-2.11.2 pyparsing-3.0.7 pyrsistent-0.18.1 pytest-4.4.1 pytest-runner-5.3.1 python-dateutil-2.8.2 python-docx-0.8.11 python-editor-1.0.4 pytz-2021.3 pyzmq-22.3.0 qtconsole-5.2.2 qtpy-2.0.0 querystring-parser-1.2.4 ray-1.9.1 redis-4.1.2 regex-2022.1.18 rouge-score-0.0.4 rsa-4.8 ruamel.yaml-0.17.20 ruamel.yaml.clib-0.2.6 s3transfer-0.5.0 sacrebleu-1.5.0 sacremoses-0.0.47 scikit-learn-1.0.2 scipy-1.7.3 sentencepiece-0.1.96 sentry-sdk-1.5.4 seqeval-1.2.2 sgmllib3k-1.0.0 shortuuid-1.0.8 simplejson-3.17.6 smart-open-5.2.1 smmap-5.0.0 soupsieve-2.3.1 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 sqlalchemy-1.3.13 sqlparse-0.4.2 srsly-2.4.2 tabulate-0.8.9 tempora-5.0.1 tenacity-8.0.1 tensorboardX-2.2 termcolor-1.1.0 terminado-0.13.1 testpath-0.5.0 thinc-8.0.13 threadpoolctl-3.1.0 tokenizers-0.10.3 torch-1.10.2 torchvision-0.11.3 tornado-6.1 traitlets-5.1.1 transformers-4.13.0 typer-0.4.0 typing-extensions-3.10.0.2 wandb-0.12.10 wasabi-0.9.0 wcwidth-0.2.5 webencodings-0.5.1 websocket-client-1.2.3 widgetsnbextension-3.5.2 wrapt-1.13.3 xxhash-2.0.2 yarl-1.7.2 yaspin-2.1.0 zc.lockfile-2.0 zipp-3.7.0\n",
      "\u001b[36mINFO\u001b[0m[0589] Taking snapshot of full filesystem...        \n"
     ]
    }
   ],
   "source": [
    "job.logs()  # show logs of building container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1230b-ab42-463a-8a41-82cfbed2f2d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run job (it runs only .py files, so we wrap our .sh script into .py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0599146-1732-4263-873f-949fcb092fc2",
   "metadata": {},
   "source": [
    "Limitations:\n",
    "1. Better to use with .py files\n",
    "2. No internet connection, so you have to load and cache models/datasets/etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5190b660-4a72-445b-a8fe-26a730abddfd",
   "metadata": {},
   "source": [
    "We also could create a Job with bash script, but we have to add several parameters.\n",
    "\n",
    "NOTE: for now, better to use .py scripts, because .sh scripts will be runned in parallel mode in case of multiple nodes/instances\n",
    "\n",
    "For now there are several additional params in Job class that doesn't mentioned in official docs, but could be useful for our tasks:\n",
    "1. type - type of script, should be \"binary\" for bash scripts\n",
    "2. region - region of instance, if set to \"A100\", will create instances with A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "aa8c286c-b0ab-4eb3-b978-4747b56fa08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a job\n",
    "# this .sh script just print list of files in current directory\n",
    "test_run_sh = client_lib.Job(\n",
    "    base_image=job.new_image,  # ID of your custom image or one of the base images\n",
    "    script=\"bash ./active_learning/examples/run_cluster_job/test.sh\",  # script to run\n",
    "    n_workers=1,\n",
    "    n_gpus=2,\n",
    "    type=\"binary\",  # for .sh scripts\n",
    "    warm_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "50d7a760-cc91-4ce9-ad24-243f55f72cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a job\n",
    "test_run = client_lib.Job(\n",
    "    base_image=job.new_image,  # ID of your custom image or one of the base images\n",
    "    script=\"./active_learning/examples/run_cluster_job/test.py\",  # script to run\n",
    "    n_workers=1,\n",
    "    n_gpus=2,\n",
    "    warm_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fa963d9a-292d-4539-a292-b52e3bcb05a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job \"lm-mpi-job-f7e6af43-643d-406f-b320-a8eb50c29ac3\" created'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the job to the queue\n",
    "test_run.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d3b65a4b-905a-41fb-8ac2-fb40ef530a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-31T14:04:53Z : lm-mpi-job-08f2a950-191c-47a1-9a22-ef033cfca39e : Completed\n",
      "2022-01-31T18:02:06Z : lm-mpi-job-135bdfb3-d611-411c-8358-7976c0a84f66 : Completed\n",
      "2022-01-28T11:01:16Z : lm-mpi-job-14eb65bd-deca-448b-ab9b-09578b19c0fa : Completed\n",
      "2022-01-28T11:35:55Z : lm-mpi-job-1734f7d1-0463-4876-ba68-de84b6d2e4fd : Completed\n",
      "2022-01-31T17:42:12Z : lm-mpi-job-185e2300-9482-455f-838b-e4a202225b0d : Completed\n",
      "2022-02-02T14:49:43Z : lm-mpi-job-1cfdb7d6-f990-49ea-a20a-1729ce1c82e5 : Completed\n",
      "2022-01-31T11:20:08Z : lm-mpi-job-1e86c50d-8c01-4bfe-8f30-930ee61d9e13 : Completed\n",
      "2022-01-31T14:52:54Z : lm-mpi-job-209f3943-159f-4268-ac0b-296f93f8c6f8 : Completed\n",
      "2022-01-28T20:19:25Z : lm-mpi-job-2b03d9de-a5d9-40f2-9a69-572fb3c2cd94 : Completed\n",
      "2022-02-02T15:06:50Z : lm-mpi-job-34ce5782-b460-491e-8a46-fc4ab53f0a43 : Completed\n",
      "2022-01-31T17:54:34Z : lm-mpi-job-42f9be16-2697-4a30-af2f-4a6fb27e5a9b : Completed\n",
      "2022-01-31T17:51:53Z : lm-mpi-job-4bf3d9ca-04c7-4fe3-af13-4ec5e336b13b : Completed\n",
      "2022-02-02T15:15:09Z : lm-mpi-job-4df1d3ab-960c-49e1-8580-b93141b63f84 : Completed\n",
      "2022-01-31T13:50:18Z : lm-mpi-job-5240c23d-398f-44e9-8624-122e39cdf1a1 : Completed\n",
      "2022-01-31T09:16:37Z : lm-mpi-job-5ed1df20-e414-4cf6-8670-f8a8c76deb82 : Completed\n",
      "2022-01-28T09:45:18Z : lm-mpi-job-61960070-7cd4-4793-938b-d9a2888f45b8 : Completed\n",
      "2022-02-02T15:26:20Z : lm-mpi-job-625d54b9-f4ba-43a2-b741-9f7b5a75f119 : Completed\n",
      "2022-02-02T15:10:29Z : lm-mpi-job-64392241-29b2-4e28-a846-7ff3d2e639f4 : Completed\n",
      "2022-01-28T11:14:11Z : lm-mpi-job-6b631db7-e9a4-4d94-a500-0496f6904f8a : Completed\n",
      "2022-01-28T11:49:36Z : lm-mpi-job-6c23fef9-6b9e-4c3a-9a83-73baf9d1b6a6 : Completed\n",
      "2022-01-28T13:15:25Z : lm-mpi-job-7035873a-e458-45b2-b55e-121fa41eaa5b : Completed\n",
      "2022-01-31T13:52:42Z : lm-mpi-job-7b2b23e0-737d-4773-8b5b-856b74f6078a : Completed\n",
      "2022-01-31T15:44:22Z : lm-mpi-job-7c527f87-23f7-46af-afee-c0e34231d8e3 : Completed\n",
      "2022-01-31T13:49:13Z : lm-mpi-job-82356760-10fd-4377-be40-7e165ebe2d06 : Completed\n",
      "2022-01-28T12:46:06Z : lm-mpi-job-826cab5e-672b-4121-9474-e46f486141b0 : Completed\n",
      "2022-02-02T15:01:04Z : lm-mpi-job-8315ec28-83d8-4532-b5bd-96abd2c7613b : Completed\n",
      "2022-02-01T10:56:22Z : lm-mpi-job-870ad7ef-b3b3-44ee-a63b-83a43ef3ad57 : Completed\n",
      "2022-01-31T15:07:57Z : lm-mpi-job-8c156963-f90d-408f-9f33-7b0fae733c25 : Completed\n",
      "2022-01-28T21:45:02Z : lm-mpi-job-90900760-2cae-4e82-ba9d-5b86905e0789 : Completed\n",
      "2022-01-31T14:25:44Z : lm-mpi-job-925961aa-5778-4c0d-9842-716640d61050 : Completed\n",
      "2022-01-31T13:31:26Z : lm-mpi-job-93a763cd-2ca5-49de-adc4-b3843bc7f1ab : Completed\n",
      "2022-02-02T15:20:49Z : lm-mpi-job-9f938b7a-23da-4e06-83c3-b3a94981f257 : Completed\n",
      "2022-01-28T20:57:35Z : lm-mpi-job-ac98212a-fa16-4635-bd76-d0c5968e2af2 : Completed\n",
      "2022-01-28T12:17:32Z : lm-mpi-job-b31e4dfd-d77f-4754-88d0-ad2ebf9bfa5b : Completed\n",
      "2022-01-28T21:22:13Z : lm-mpi-job-b4dfe6ca-80c3-4162-9a4d-7cd023c53948 : Completed\n",
      "2022-01-28T19:25:54Z : lm-mpi-job-b70d9271-2216-4865-93b0-a349764e9c50 : Completed\n",
      "2022-01-28T10:45:46Z : lm-mpi-job-c41e39ca-9471-4798-9b4d-eee3959eff4e : Completed\n",
      "2022-02-01T10:52:08Z : lm-mpi-job-c8eae5ec-6619-4f62-943f-fd86408412a6 : Completed\n",
      "2022-02-02T14:44:29Z : lm-mpi-job-cbd0bf82-edfb-459f-9296-4146b6c3b456 : Completed\n",
      "2022-01-28T09:58:58Z : lm-mpi-job-cd923f85-1001-42c2-9cfb-929d7bc3dbfa : Completed\n",
      "2022-01-31T18:54:19Z : lm-mpi-job-d371d83a-4f6e-4e95-929b-c0a7e61eacf9 : Completed\n",
      "2022-01-31T15:38:58Z : lm-mpi-job-d7baac0d-18a1-457a-a530-aab7aa4584d3 : Completed\n",
      "2022-01-31T14:20:16Z : lm-mpi-job-e0f66f88-861f-40a2-b4ed-ccee3ab60363 : Completed\n",
      "2022-02-02T15:28:10Z : lm-mpi-job-e2bf21a0-6529-4aea-a5d8-8eb051a0eb58 : Completed\n",
      "2022-01-31T14:27:24Z : lm-mpi-job-e623bfaa-d0a9-4323-96b1-1a77277539b2 : Completed\n",
      "2022-01-31T15:43:19Z : lm-mpi-job-e9f3f8ee-0294-4310-b9e5-236d0b2023cc : Completed\n",
      "2022-01-31T15:47:51Z : lm-mpi-job-ef5b6e66-50f4-4acc-ab85-b1b491661878 : Completed\n",
      "2022-02-02T15:37:19Z : lm-mpi-job-f7e6af43-643d-406f-b320-a8eb50c29ac3 : Completed\n",
      "2022-01-31T13:27:37Z : lm-mpi-job-f95f17f4-9aa7-443d-8c7f-407c73734c1b : Completed\n",
      "2022-01-31T12:14:31Z : lm-mpi-job-fbca5b89-e3ed-485d-9543-4e700ce707c2 : Completed\n",
      "2022-01-31T15:51:40Z : lm-mpi-job-fbcfe043-6c97-44a5-b4d7-5ade9b223fed : Completed\n",
      "2022-01-28T11:52:50Z : lm-mpi-job-fe03c4e1-60f2-4eb7-ac09-a02fbe955255 : Completed\n"
     ]
    }
   ],
   "source": [
    "# list of all your jobs\n",
    "# also shown at UI\n",
    "client_lib.jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602376ff-5bda-4d2d-aac7-c683d08e02b7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show logs of the job\n",
    "test_run.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc24cce-185f-4c52-adea-d5c303c7baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command also show logs of a job, but get it by ID\n",
    "client_lib.logs(\"lm-mpi-job-fbcfe043-6c97-44a5-b4d7-5ade9b223fed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f7f298fd-4605-4f43-aab8-534439e1cc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job \"lm-mpi-job-bff0fc50-49d6-49a8-a5ad-e01dc3ad477a\" deleted'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can kill the job, using job ID\n",
    "client_lib.kill(\"lm-mpi-job-bff0fc50-49d6-49a8-a5ad-e01dc3ad477a\")\n",
    "# or using task\n",
    "# test_run.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c549da4d-32a7-4448-9745-74007c2dd358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error 404 {\"reason\":\"No such job. Job_name = lm-mpi-job-fe3ce5c3-9d1d-4f47-b1b2-4a82dc8c9253\",\"status\":\"error\"}\\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_lib.kill(\"lm-mpi-job-fe3ce5c3-9d1d-4f47-b1b2-4a82dc8c9253\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f5e1b-c040-4ec8-a206-988e4891607c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531be4a8-f825-41b1-9452-b865426b8053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
